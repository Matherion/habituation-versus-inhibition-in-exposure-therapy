---
title: "Habituation versus inhibition in exposure therapy - literature synthesis"
author: "Pepijn van der Hulle, Gjalt-Jorn Peters, Eva de Hullu & Jacques van Lankveld"
date: "`r format(Sys.time(), '%H:%M:%S on %Y-%m-%d %Z (GMT%z)')`"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
########################################################################
### Load packages
########################################################################
 
require('userfriendlyscience');  ### For convenience functions, e.g. 'safeRequire'
safeRequire('here');             ### To easily access files using 'relative paths'
safeRequire('plyr');             ### For easily processing and restructuring data
safeRequire('dplyr');            ### Also for easily processing and restructuring data
safeRequire('purrr');            ### Iteration and the %||% operator
safeRequire('lubridate');        ### For working with dates
safeRequire("googlesheets");     ### To import data from google sheets in metabefor
safeRequire('jsonlite');         ### To import a list of country codes in metabefor
safeRequire('knitr');            ### For kable
safeRequire('ufs');              ### 
safeRequire('data.tree');        ### To work with data structured in a tree in metabefor
safeRequire('devtools');         ### To install metabefor from github repo
                                 ### ... Which we then do here:
devtools::install_github("Matherion/metabefor");
require('metabefor');

########################################################################
### Settings
########################################################################

### By default hide R code
knitr::opts_chunk$set(echo = FALSE);
knitr::opts_chunk$set(comment = NA);

### Set path for query hit exports
queryHitExportPath <- here::here("queries");

### Set path for screening
screeningPath <- here::here("screening");

### Set path for any preliminary studies/work
prePath <- here::here("pre");

### Set path for extraction script template
extractionScriptTemplatePath <- here::here("extraction");

### Create object to keep track of queries
queries <- list();

### Simple function to correctly capture figures
figCap <- function(caption) {
  figCapCounter <-
    ifelse(is.null(getOption('figCapCounter')),
           0,
           getOption('figCapCounter'));
  figCapCounter <- figCapCounter + 1;
  options(figCapCounter = figCapCounter);
  return(paste0("Figure ", figCapCounter, ": ", caption));
}

### Set figure counter to 0
options(figCapCounter = 0);

```

## Pilot data {.tabset}

### Overview and decisions

There were no comments about fear hierarchy, fear level, occasional reinforced extinction, removal of safety signals, variability, retrieval cues, multiple contexts.

#### Fear monitoring

*"The fear level of the participant is being monitored throughout the exposure trial."*

- Could also include ‘affect labelling’ more generally.

This could include affect labelling, but a crucial condition is that fear monitoring always involves monitoring the *level* of the emotion. We decide that this is sufficiently clear from the definition as we formulated it now; this should exclude affect labelling exercises where monitoring is not explicit.

#### Expectancy statement

*"Expectancies for aversive events are explicitly stated before the start of the exposure trial."*

- I agree this is important, the only thing would be whether it can be shown to be an therapy ingredient - even without explicitly stating and disconfirming it, expectancies are likely to be activated and contradicted.
- Expectancies for aversive events are explicitly stated before the start of the exposure trial and monitored throughout the exposure trial (perhaps better called expectancy monitoring)

Regarding the first point, this is a methodological point; if indeed, in many therapy sessions/control groups, expectancies will be activated as 'usual care', the effect size will be very low. However, this would then accurately estimate the effects than can be expected of this therapy ingredient. We decide to not make any revisions based on this comment.

Regarding the second point, we decide to add monitoring as another therapy ingredient in addition to baseline statement of the expectancies. As formulation, we will use "Expectancies for aversive events are monitored throughout the exposure trial."

#### Learning consolidation

*"Following the exposure trial, the learning is consolidated by asking participants to judge what they learned regarding the non-occurrence of the feared event, discrepancies between what was predicted and what occurred."*

- I would use another term than consolidation as this also refers to the process of memory storage/stabilisation that is also often spoken of in fear learning/extinction.

We decide to substitute 'evaluation' for consolidation. For clarity, we also rephrase the definition to: "Following the exposure trial, the participants are asked to evaluate what they learned regarding the non-occurrence of the feared event, discrepancies between what was predicted and what occurred."

#### Expectancy violation

*"The end of the exposure trial is determined by expectancy reduction to a certain level."*

- Could also be stated as ‘prediction error’. It’s a little difficult whether the expectancy violation should be ‘reduced to a certain level’, or whether it is instead a binary thing: you make the explicit and specific prediction and test it in the exposure. Could expectancy statement and expectancy violation even be combined to refer to a ‘behavioral test’ - as in CBT where the cognitions/expectations are treated as a hypothesis and the exposure functions as a behavioral test of them

In discussing this point, we realise that in fact, this therapy ingredient and 'Fear level' describe specific instances of generic 'termination criteria' that can be described as a combination of two decisions. First, does termination occur based on the monitored level of a psychological variable, or based on prespecified criteria that operationalise expectations regarding the influence of the exposure on the level of a psychological variable. Second, does this variable relate to somebody's fear or their expectancies? The possible combinations would therefore be:

1. Level-based termination (fear): The end of the exposure trial is determined by fear reduction to a certain level, as measured through monitoring (e.g. if this therapy ingredient is coded, 'Fear monitoring' must always also be coded).
2. Level-based termination (expectancy): The end of the exposure trial is determined by expectancy reduction to a certain level, as measured through monitoring (e.g. if this therapy ingredient is coded, 'Expectancy monitoring' must always also be coded).
3. Exposure-based termination (fear): The exposure trial ends when prespecified conditions that are based on expected effects of the exposure on fear are met (e.g. exposure for a specific period).
4. Exposure-based termination (expectancy): The exposure trial ends when prespecified conditions that are based on expected effects of the exposure on expectancies are met (e.g. exposure for a specific period).
5. Exposure-based termination (nonspecific): The exposure trial ends when prespecified conditions are met (e.g. exposure for a specific period), where it is not specified what these conditions are based on.

Note that we realise that not all combinations are plausible or realistic from the theoretical frameworks employed. However, the only cost of retaining them is that some may never be coded, which is a lower cost than omitting an therapy ingredient that does occur.

We will therefore also remove therapy ingredients 'Expectancy violation' and 'Fear level'.

#### Lessen overestimation

*"Cognitive interventions designed to lessen probability overestimation (e.g., “I am unlikely to be bitten by the dog”) and perceived negative valence (e.g., “It is not so bad to be rejected”) occur."*

- dit is 1 kant van angst; de andere is de mate waarin iemand zelfvertrouwen (self-efficacy; problem solving/coping) heeft een probleem aan te kunnen (CBT kan zich ook op die kant richten om angst te verminderen)
- It would depend on when this occurs: if exposure therapy works by forcing a prediction error to update beliefs, then some theorists would say that lessening overestimation before exposure would be counterproductive, as it would lessen the contrast between what is expected and what occurs, and reduce inhibitory learning.
- The formulation is somewhat obscure. What exactly is the intervention?

The first point is true; increasing self/response efficacy, coping skills, et cetera can also plausibly help reduce fear or change expectancies, and thus contribute to exposure therapy effectivess. However, such an intervention would not constitute exposure therapy per se, and therefore we decide to not code this element. (Note that we are aware that inclusion of a self-efficacy intervention might be a precondition for the effectiveness of some of these other therapy ingredients; but modeling such interactions goes far beyond the scope of what is feasible in this project.)

The second point is an excellent point, and directly concerns the goal of this review: whether this therapy ingredient is included in a therapy would be indicative of the theoretical perspective from which the therapy was designed.

The third point is also a good point; however, given the breadth of interventions applied to this end, we see no possibilities to specify this more explicitly. We will therefore, for now, retain this definition.

#### Deepened extinction

*"Combination of multiple cues (internal and/or external) during exposure therapy, after initially conducting some exposure to each cue in isolation."*

- Could also have a separate thing for enhancing extinction learning with pharmacological means? The same could go for habituation (a drug taken to reduce arousal during exposure could make habituation more rapid).

This is a good point; we decide to add an additional therapy ingredient:

1. Pharmacological enhancement: Pharmacological means are used to support the therapy.

#### Reconsolidation

*"The phobic stimulus is introduced for a brief period about 30 minutes before repeated trials of exposure."*

- I would say ‘retrieval-extinction’ rather than reconsolidation. I the one case, you simply state what is occurring (brief retrieval, then extinction), whereas in the other a specific process is inferred. There is a lot of conflicting evidence about whether retrieval-extinction procedures are really reconsolidation-based.

One participant remarked that 'reconsilidation' may be a misnomer; 'retrieval-extinction' may be more accurate. However, this participant did not think this was a redundant therapy ingredient to code. Consistent with our earlier decision to avoid 'consolidation', we will follow this suggestion and rename this therapy ingredient to "Brief pre-exposure".

#### Omissions

- Mogelijk nog het aantal behandelingen.

Indeed, number of treatments is important to code.

- En waarschijnlijk ook goed om onderscheid te maken in typen angst: bijvoorbeeld in termen van complexiteit (bijv. spinnenangst vs. sociale angst).

This is a good point. We will code this using the DSM categories.

- One of the things I thought of was that sometimes a pharmacological agent is used to enhance inhibitory learning. Perhaps: ‘pharmacological enhancement’ or something like that.
- The reference to reconsolidation is questionable as I noted above, in that we do not know whether reconsolidation is what is occurring. Also though, if a reconsolidation approach is taken and reconsolidation is what is believed to be happening, then it would be neither a habituation nor an inhibitory learning approach. The idea that people focusing on reconsolidation in exposure are pushing is that rather than inhibitory memories being formed, the original memory is directly updated.

Both points have been dealt with above.

- self-efficacy (Bandura)

We dealt with this above, as well.

- contingency management (rewarding courageous behaviors (by praise or material rewards by therapist and carers; self-reward; ignoring anxious behaviors)

This is an important omission. We will include this therapy ingredient:

1. Contingency management: Any use of rewards on the basis of progress in the exposure therapy.

- It’s maybe implicitly stated in the ‘fear monitoring’ ingredient, but I would add ‘fear eliciting’: one needs to be sure the participant is feeling anxious/experiencing fear in order for habituation to be possible

We discussed this and decided that this is implicit in the 'Nature of exposure' entity that will be extracted. On the one hand, exposure should normally always result in fear elicitation. On the other hand, if we do want to extract/code this, it should be as a manipulation check of the variable 'fear'; this is about therapy fidelity, not therapy ingredients.

### Details

```{r process-pilot-data, results="asis"}

preDat <- importLimeSurveyData(datafile=file.path(prePath, "data", "survey_774372_R_data_file.csv"),
                               scriptfile=file.path(prePath, "data", "survey_774372_R_syntax_file.R"),
                               categoricalQuestions = c("expertise"));

varsToShow <- c(grep('corrections_', names(preDat), value=TRUE),
                'omissions',
                'expertise',
                'expertise_other',
                'comments');

for (currentVar in varsToShow) {
  ufs::cat0("\n\n#### ", currentVar, "\n\n");
  ufs::cat0(paste0("\n- ", preDat[isTrue(preDat$lastpage==1),
                                  currentVar], "\n"));
}

```

<!--------------------------------------------------------------------->
<!-- Set up of first query (done before the corresponding header, as -->
<!-- the date in that header is read from this object) ---------------->
<!--------------------------------------------------------------------->

```{r first-query-setup}
queries[[length(queries) + 1]] <-
  list(date = ymd("2018-08-28"),
       query = query_requiredConcepts(conceptName="Exposure therapy query",
                                      query_conceptTerms(conceptName = "Cognitive Behavioral Therapy",
                                                         "cognitive behavio* therapy",
                                                         "cbt"),
                                      query_conceptTerms(conceptName = "Exposure Therapy",
                                                         "exposure"),
                                      query_conceptTerms(conceptName = "Target population",
                                                         "child*",
                                                         "adolescent*",
                                                         "youth"),
                                      query_conceptTerms(conceptName = "Disorder",
                                                         "anxiety",
                                                         "fear")),
       databases = list(psycinfo = list(interface = "ebsco",
                                        fileFormat = "ris"),
                        pubmed = list(interface= "pubmed",
                                      fileFormat = "ris")),
       fields = "title, abstract");

### Note that PsycINFO subsumes PsycARTICLES, and PubMed subsumes MEDLINE (see
### "Is PsycARTICLES cross-linked with any outside databases or journals?" at
### http://www.apa.org/pubs/databases/psycarticles/faq.aspx for PsycINFO and
### and http://askus.library.tmc.edu/faq/2018 for MEDLINE

```

## First query, executed at: `r queries[[1]]$date;`

The first query is:

```{r query1-visual, screenshot.force=FALSE}
plot(queries[[1]]$query);
```

In this plot, the 'AND' operator is visualised by a solid line, while the 'OR' operator is visualised by a dotted line.

In this query, the searched terms must occur in entries' `r queries[[1]]$fields` fields.

In the interface language of the PubMed interface to the PubMed database and the Ebscohost and Ovid interfaces to a variety of databases such as PsycINFO, PsycArticles, and MedLine, this query renders as:

```{r}
query_toInterfaceLang(queries[[1]]$query,
                      fields=queries[[1]]$fields);
```

This query was run at `r queries[[1]]$date;` in PubMed (XXXX hits; file saved as <code>pubmed-`r queries[[1]]$date`.ris</code>) and PsycINFO accessed through EbscoHost (XXXX hits; file saved as <code>psycinfo-`r queries[[1]]$date`.ris</code>), and exported to RIS format (called 'MEDLINE' in PubMed). The RIS files were then imported in R using `metabefor`.

```{r echo=TRUE, eval=TRUE}

### Import PsycINFO hits
firstQueryIteration_psycinfo <-
  importRISlike(file.path(queryHitExportPath,
                          queries[[1]]$date,
                          paste0(queries[[1]]$date, "--",
                                 queries[[1]]$databases[[1]]$interface, "--",
                                 names(queries[[1]]$databases)[1], ".",
                                 queries[[1]]$databases[[1]]$fileFormat)),
                encoding="native.enc");

### Import PubMed hits
firstQueryIteration_pubmed <-
  importRISlike(file.path(queryHitExportPath,
                          queries[[1]]$date,
                          paste0(queries[[1]]$date, "--",
                                 queries[[1]]$databases[[2]]$interface, "--",
                                 names(queries[[1]]$databases)[2], ".",
                                 queries[[1]]$databases[[2]]$fileFormat)),
                encoding="native.enc");

### Merge the two sets of hits
firstQueryIteration <-
  findDuplicateReferences(primaryRefs = firstQueryIteration_psycinfo,
                          secondaryRefs = firstQueryIteration_pubmed,
                          duplicateFieldValue = "dupl",
                          newRecordValue = "PubMed",
                          duplicateValue = "duplicate (both PsycINFO and PubMed)",
                          originalValue = "PsycINFO");

### Generate bibtex keys
firstQueryIteration$output$records <-
  generateBibtexkeys(firstQueryIteration$output$records);

### Add query date identifier to bibtex keys
firstQueryIteration$output$records$bibtexkey <-
  paste0(firstQueryIteration$output$records$bibtexkey,
         "-", gsub("-", "", queries[[1]]$date));

screening1_filename_pre <- paste0(queries[[1]]$date, "-screening.bib");
screening1_filename_post <- paste0(queries[[1]]$date, "-screened.bib");

### Export the hits to bibtex for screening in JabRef
sysrevExport(firstQueryIteration,
             filename=file.path(screeningPath,
                                screening1_filename_pre),
             screeningType=NULL);

```

The merged list of query hits has now been exported to file <code>`r screening1_filename_pre`</code> in directory "screening" and can be opened using JabRef, which can be downloaded from https://www.fosshub.com/JabRef.html.

## JabRef configuration

When opening a bibliographic library (i.e. a file with the extension `.bib`) in JabRef, it will show the entry table, which is a convenient way to inspect all entries (hits, references, articles, etc) in the library. To prepare JabRef for screening, two settings are important.

First, to change the fields that are visible in the overview table of all references (i.e. the entry table), open the 'Options' drop-down menu and select 'Preferences'. In the preferences dialog, open the 'Entry table columns' section:

![Figure 1: Screenshot of JabRef preferences dialog when the 'Entry table columns' section is opened.](../img/jabref--preferences--entry-table-columns.png)

There, the columns shown in the entry table can be edited in the 'Entry table columns' sections. A bit confusingly, this is done by adding *rows* in the table shown in this dialog. Each 'row' in this table represents a column in the entry table.

Note that in bibtex (and therefore JabRef), you can create new fields on the fly. In this case, use field 'screening1' for screening the hits of this first screening iteration: simply add this field name as a 'row' (column) in the entry table. This will show, for every entry, the contents of that field (if it has any).

Second, you need to be able to edit the content in that field. The entry table is very convenient to maintain an overview of the entries in the database, but cannot be used for editing. To edit an entry, double click it in the entry tabel. This opens the entry editor, which has a number of tabs. Each tab shows a number of fields which can then be edited.

These tabs can be configured by setting the 'General fields'. Open the 'Options' drop-down menu and select 'General Fields' to configure which fields are available in the different tabs when opening an entry. 

![Figure 2: Screenshot of JabRef dialog used to set the general fields.](../img/jabref--set-general-fields.png)

Add a dedicated field for the reviewing, showing only the title, abstract, and `screening1` fields. This allows you to focus on the relevant information while ignoring irrelevant and potentially biasing information (such as year, journal, and authors). Each row in this text area shows one tab. The first term on each row is the tab's name, followed by a colon (`:`) and then the fields shown in the tab, separated by semicolons (`;`). For example, you could add the following row:

`Screening Round 1:title;abstract;screening1`

## Screening process

For every entry, add the following text in the 'screening' field:

- If it is excluded, add the reason, specifically (these are ordered progressively; i.e. if one of the criteria matches, apply it and move on to the next entry):
    - **`dupl`** if the study is a duplicate of another entry;
    - **`noexper`** if the study does not have an experimental design;
    - **`nopopul`** if the study did not sample participants younger than 18 years;
    - **`noexpos`** if the study did not compare two groups that differ in the treatment in terms of exposure as a part of cognitive behavioral therapy;
    - **`nophobia`** if the study did not concern treatment for phobia disorders;
- If it is included, add **`incl`**.

So once JabRef is opened, when screening, make sure that the 'screening1' field is shown in the entry table (i.e. that it is one of the entry table columns), and create one entry editing tab using 'General Fields' that contains the fields `title`, `abstract`, and `screening1`. You can then use this tab for the screening. It is also convenient to show field `dupl` in either the entry table or the screening tab in the entry editor, because for duplicate records (that were identified as such - the algorithm may miss some duplicates of course), that field contains the text `dupl`.

Make sure to save the database with query hits under a different name than <code>`r screening1_filename_pre`</code>. That is important because file <code>`r screening1_filename_pre`</code> will get overwritten if this R Markdown file is executed again. This file will not require any adjustments if you name the database <code>`r screening1_filename_post`</code>.

### Screening results {.tabset}

#### Overview

This is an overview of the screening results. The details for the sources to include are listed in the second tab.

```{r query-1-import-screened-hits-overview}

firstQueryScreened <-
  metabefor::importBibtex(file.path(screeningPath,
                                    screening1_filename_post));

userfriendlyscience::freq(firstQueryScreened$records$screening1);

```

#### Details

```{r query-1-import-screened-hits-details, results='asis'}

firstQueryScreened$records %>%
  dplyr::filter(grepl("incl", screening1)) %>%
  dplyr::rowwise() %>%
  dplyr::do(
    data.frame(txt=paste0("\n\n##### ", .$bibtexkey, "\n\n",
                          .$author, " (", .$year, ") ",
                          .$title, ". ", .$journal, ". <a href='https://doi.org/",
                          .$doi, "'>", .$doi, "</a>\n\n",
                          .$abstract),
               stringsAsFactors = FALSE)
  ) %>%
  unlist() %>%
  cat(collapse="\n");

### Maybe start working with
# firstQueryScreened$records$bibtype <- firstQueryScreened$records$recordtype;
# row.names(firstQueryScreened$records) <- firstQueryScreened$records$bibtexkey
# RefManageR::PrintBibliography(RefManageR::as.BibEntry(head(firstQueryScreened$records, 1)),
#                               .opts=list(no.print.fields=setdiff(names(firstQueryScreened$records),
#                                                                  c('author',
#                                                                    'title',
#                                                                    'date',
#                                                                    'journal'))));

```

<!-- ## Second query, executed at: 2018-05-23 -->

<!-- The query was updated to: -->

<!-- ``` -->
<!-- NEWQUERY -->
<!-- ``` -->

<!-- This was run at 2018-05-23 in PubMed (61 hits) and PsycINFO accessed through EbscoHost (72 hits), and exported to the RIS format (called 'medline' in PubMed). The RIS files were then imported in R using `metabefor`. -->

```{r echo=TRUE, eval=FALSE}

### Import PsycINFO hits
secondQueryIteration_psycinfo <-
  importRISlike(file.path(queryHitExportPath,
                          "psycinfo-2018-05-23.ris"),
                encoding="native.enc");

### Import PubMed hits
secondQueryIteration_pubmed <-
  importRISlike(file.path(queryHitExportPath,
                          "pubmed-2018-05-23.ris"));

### Merge the two sets of hits
secondQueryIteration <-
  findDuplicateReferences(primaryRefs = secondQueryIteration_psycinfo,
                          secondaryRefs = secondQueryIteration_pubmed,
                          duplicateFieldValue = "dupl (2nd)",
                          newRecordValue = "PubMed (2nd)",
                          duplicateValue = "duplicate (both PsycINFO and PubMed; 2nd)",
                          originalValue = "PsycINFO (2nd)");

### Generate bibtex keys
secondQueryIteration$output$records <-
  generateBibtexkeys(secondQueryIteration$output$records);

### Add query date identifier to bibtex keys
secondQueryIteration$output$records$bibtexkey <-
  paste0(secondQueryIteration$output$records$bibtexkey,
         "-20180523");

### Import results from first query (these have been screened now)
firstQueryIteration_screened <-
  importBibtex(file.path(screeningPath,
                         "2018-05-14-screening#1.bib"));

### Merge the screened reference database from the first query
### with the database from the second query
secondQueryIteration_merged <-
  findDuplicateReferences(primaryRefs = firstQueryIteration_screened,
                          secondaryRefs = secondQueryIteration,
                          duplicateFieldValue = "Screened in first iteration",
                          newRecordValue = "From second query",
                          duplicateValue = "From first query (screened in first iteration)",
                          originalValue = "screening1");

### The new records are stored in secondQueryIteration_merged$output$newRecords, so we
### can copy these to the database from the first screening. We also store the entire
### database so that we can document the process (and if need be, check whether anything
### went wrong).

secondScreening <- firstQueryIteration_screened;

secondScreening$output$records <- rbind.fill(secondScreening$output$records,
                                             secondQueryIteration_merged$output$newRecords);

### Export the hits to bibtex for screening in JabRef
sysrevExport(secondQueryIteration_merged,
             filename=file.path(screeningPath,
                                "2018-05-23-fully-merged-database.bib"),
             screeningType="screening");

sysrevExport(secondScreening,
             filename=file.path(screeningPath,
                                "2018-05-23-screening.bib"),
             screeningType="screening");

```

<!-- The merged bibliographic database has been stored in the screening path (`r screeningPath`), to file `2018-05-23-screening.bib`. This file can now be opened in JabRef, and should be saved to a different filename before any edits are made (because, after all, the file named `2018-05-23-screening.bib` will be overwritten every time this script runs). -->

<!-- In this merged database, field 'screening1' has been preserved. Records where this field is empty, therefore, are from the second query, and should be screened in the second screening sweep. -->


## Data extraction

### The extraction script (.rxs) {.tabset}

#### Generation of the extraction script

We will use a metabefor extraction script for the extraction of the data. The idea of this script is to extract the data from the original sources with a minimum of interpretation. The data is extracted into a machine-readable format, which then allows competely transparent further processing and synthesis.

These scripts are generated on the basis of two tables/spreadsheets. The first contains the entities to extract, such as study year, sample size, how variables were operationalised, and associations that were found. The second contains the valid values for each entity, to allow efficiently providing coders with examples, instructions, and to allow easy verification of the input.

The logged messages from this process are available in this section under the tab 'Logged messages', and the generated extraction script template (which is also written as a file to the repository) is included in a text area in the 'Extraction script template' for convenient inspection.

#### Logged messages

```{r extraction-script-generation}

sheetsURL <- paste0("https://docs.google.com/spreadsheets/d/",
                    "1TpdpB926luKVy2tCwBusFkxZ7xv-BzdzzBjmOU26PI8");

valueTemplatesSheet <- "valueTemplates";
entitiesSheet <- "entities";

fullObject <-
  rxs_fromSpecifications(gs_url = sheetsURL,
                         entitiesFilename = file.path(extractionScriptTemplatePath,
                                                      "entities-local-copy.csv"),
                         valueTemplatesFilename = file.path(extractionScriptTemplatePath,
                                                            "valueTemplates-local-copy.csv"),
                         localBackup = list(entities = file.path(extractionScriptTemplatePath,
                                                                 "entities-local-copy.csv"),
                                            valueTemplates= file.path(extractionScriptTemplatePath,
                                                                      "valueTemplates-local-copy.csv"),
                                            definitions = NULL),
                         outputFile = file.path(extractionScriptTemplatePath,
                                                "extractionScriptTemplate.rxs.Rmd"),
                         returnFullObject = TRUE);

```

#### Extraction script template

```{r extraction-script-template, results="asis"}
cat("\n\n<pre><textarea rows='40' cols='124' style='font-family:monospace;font-size:11px;white-space:pre;'>",
    unlist(fullObject$rxsTemplate),
    "</textarea></pre>\n\n",
    sep="\n");
```

### Software considerations

To do the actual extraction, there are two general routes an extractor can take. The first is to use R Studio. The advantage of using R Studio is that, because each extraction script file (rxs file) is in fact an R Markdown file, it can be rendered into a report for the extracted study immediately. This can show whether any mistakes were made during extraction, and easily allows the extractor to check the results of their labour.

However, a disadvantage of R Studio is that R Markdown files are always wrapped. Wrapping means that to prevent the need for horizontal scrolling, long lines of text are displayed on multiple lines. Wrapping is almost always very useful. Text processors, for example, always wrap; text in books is always wrapped; and so is online content.

However, extraction scripts contain very long lines when closely related entities are extracted in list form; in that case, their explanation and examples are placed as comments (preceded by R's comment symbol, `#`) behind the entities and values to extract, which can look very confusing if lines are wrapped.

RStudio does use syntax coloring to clearly indicate which parts of the extraction script are comments and which parts are values, but still, extractors might find this confusing.

The second option, therefore, is to use an external editor. For extractors working in a Windows environment, Notepad++ is recommended; for extractors working in a Mac OS environment, BBEdit is recommended (extractors using a Linux distro probably already have their preferred text editors).

![`r figCap('Notepad++ when no file has been loaded yet')`](../img/notepadplusplus--empty.png)

#### Downloading the software

Working with RStudio requires installing R as well.

- R can be downloaded from [this link](https://cloud.r-project.org/) (specifically from [this link](https://cloud.r-project.org/bin/windows/base/) for Windows, from [this link](https://cloud.r-project.org/bin/macosx/) for MacOS, and through [this link](https://cloud.r-project.org/bin/linux/) for Linux).
- RStudio can be downloaded from [this link](https://www.rstudio.com/products/rstudio/download/#download).
- Notepad++ can be downloaded from [this link](https://notepad-plus-plus.org/download).
- BBEdit can be downloaded from [this link](https://www.barebones.com/products/bbedit/download.html) (the free version suffices).

#### The extraction process

When extracting articles, an extractor takes the following steps:

- Open the article (this usually means opening the relevant PDF in the `pdfs` directory).

- Copy the extraction script template to a new file in the `extraction` directory.

- Give the new file a name conform the following convention: a list of the last names of all authors, all in lower case (i.e. without capitals), separated by dashes (`-`), and ending with the year of the study, separated from the list of author names by two dashes (`--`), and ending with the extraction script extension (`.rxs.Rmd`). Thus, the filename should look something like this: `boys-marsden--2003.html`.

- Open the new (and newly renamed) extraction script in the editor of choice (see the 'Software considerations' section above).

- If you haven't looked at the extraction script yet, study it. If you encounter anything you're uncertain about, contact another team member to ask them to explain it.

- In the extraction script, scroll to the line containing the text `START: study (ROOT)`.

- Scroll downwards through the extraction script, completing each extractable entity as you encounter it. Often, the first entity will be the study identifier (usually a Digital Object Identifier or DOI).

- Once you have completed the extraction script, if you use RStudio, you can 'render' or 'knit' it by clicking the 'Knit' button at the top. This will show you what you extracted. If you made any errors (e.g. forgot a comma, or a single or double quote, or forgot to open or close a parenthesis, or mistyped a variable name, etc), this should become clear at this point. Correct any errors. (If you use another editor, you won't be able to check this at this point.)

- Repeat these steps for the next article.

If you run into any problems, clearly write them down, and depending on what you agreed with your team members, accumulate these issues and discuss them at the next meeting, or immediately pass them on using whichever medium you use.

## List of therapy ingredients

This table shows the list of therapy ingredients to be coded, for easy access and scrutiny, since it's so central to this study.

```{r therapy-ingredient-list}

data.frame(Name=fullObject$rxsStructure$parsedEntities$extractionScriptTree$methods$variables$treatments$Get('title'),
           Description=fullObject$rxsStructure$parsedEntities$extractionScriptTree$methods$variables$treatments$Get('description')) %>%
  knitr::kable();

```
